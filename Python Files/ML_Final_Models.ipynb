{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59084d0",
   "metadata": {
    "id": "f59084d0"
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries for data analysis and modeling\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "import pandas as pd  # For data manipulation\n",
    "import numpy as np  # For numerical operations\n",
    "import seaborn as sns  # For advanced data visualization\n",
    "from sklearn import datasets, linear_model, metrics  # For machine learning models and metrics\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler  # For data preprocessing\n",
    "from sklearn.linear_model import LinearRegression  # For building a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y2BSSKTrFUNp",
   "metadata": {
    "id": "Y2BSSKTrFUNp"
   },
   "outputs": [],
   "source": [
    "# Set the display option to show all columns when printing DataFrames\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a9b17",
   "metadata": {
    "id": "d17a9b17"
   },
   "outputs": [],
   "source": [
    "# Read a CSV file located at the specified path and load it into a DataFrame 'df'\n",
    "df = pd.read_csv(\"C:/Users/sampa/OneDrive/Desktop/sannidhi/Masai/Projects/Practo/data/model_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1962919b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "1962919b",
    "outputId": "21baa6ca-e9b0-4dc6-ed5d-a829254ddd98",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame 'df'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a3b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dimensions (number of rows and columns) of the DataFrame 'df'\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cea5c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the column names of the DataFrame 'df'\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23887824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map new column names to existing column names\n",
    "new_column_names = {\n",
    "    'City_Bangalore': 'Bangalore',\n",
    "    'City_Delhi': 'Delhi',\n",
    "    'City_Mumbai': 'Mumbai'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in the DataFrame 'df' using the 'new_column_names' dictionary and apply changes in place\n",
    "df.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478ae4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3478ae4b",
    "outputId": "5bb44dfa-b20b-4533-cdb8-8d1189ba6b99",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the count of missing values (NaN) for each column in the DataFrame 'df'\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7242fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names representing numerical features\n",
    "num = ['Year_of_experience', 'dp_score', 'npv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cbb7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance for feature scaling\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the StandardScaler 'sc' to standardize the numerical columns specified in 'num' in the DataFrame 'df'\n",
    "df[num] = sc.fit_transform(df[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bbf2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the subset of the DataFrame 'df' containing only the numerical columns specified in 'num'\n",
    "df[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15bb20",
   "metadata": {
    "id": "ab15bb20"
   },
   "outputs": [],
   "source": [
    "# Splitting the DataFrame 'df' into features (X) and target variable (y)\n",
    "X = df.drop(\"consultation_fee\", axis=1)  # Features (all columns except 'consultation_fee')\n",
    "y = df['consultation_fee']  # Target variable ('consultation_fee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504ebd1",
   "metadata": {
    "id": "8504ebd1"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e43fba7",
   "metadata": {
    "id": "4e43fba7"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for machine learning and regression modeling\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into train and test sets\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso  # For linear regression models\n",
    "from sklearn.tree import DecisionTreeRegressor  # For decision tree regression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor  # For ensemble regression models\n",
    "from sklearn.svm import SVR  # For support vector regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # For regression performance evaluation\n",
    "from xgboost import XGBRFRegressor  # For XGBoost-based regression\n",
    "# from tensorflow.keras.models import Sequential  # For deep learning models (commented out)\n",
    "# from tensorflow.keras.layers import LSTM, Dense  # For deep learning models (commented out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537cee9",
   "metadata": {
    "id": "f537cee9"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary 'mod' containing different regression models as values\n",
    "mod = {\n",
    "    'Linear Regression' : LinearRegression(),\n",
    "    'Decision Tree Regressor' : DecisionTreeRegressor(),\n",
    "    'Random Forest Regressor' : RandomForestRegressor(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'Support Vector Regression' : SVR(),\n",
    "    'Ridge Regression' : Ridge(alpha=0.5),\n",
    "    'Lasso Regression' : Lasso(alpha=0.1),\n",
    "    'XGBoost model' : XGBRFRegressor(n_estimators=100, random_state=42),\n",
    "    'AdaBoost Regressor' : AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a48f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a4a48f0",
    "outputId": "d3d2d52f-0c6d-42bf-db83-d21816fd3720",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate through each regression model and evaluate its performance\n",
    "for name, model in mod.items():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name)\n",
    "    print(f'mse: {mean_squared_error(y_test, y_pred)} rmse: {mean_squared_error(y_test, y_pred)**0.5}: r2_score: {r2_score(y_test, y_pred)}')\n",
    "    print('***************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7641086",
   "metadata": {},
   "source": [
    "## CV on AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec24e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f7ec24e3",
    "outputId": "1bfd2cc2-f586-4572-ac5b-55ccf0975c7c"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [200,300,400,500],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "base_estimator = DecisionTreeRegressor()\n",
    "\n",
    "# Create the AdaBoost regressor\n",
    "adaboost = AdaBoostRegressor(base_estimator=base_estimator)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=adaboost, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, error_score='raise')\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yNVtsbGdhClq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNVtsbGdhClq",
    "outputId": "a5ad2716-86e2-46fe-ab81-0a1c525b8ba8"
   },
   "outputs": [],
   "source": [
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2S=r2_score(y_test,y_pred)\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best MSE:\", mse)\n",
    "print(\"R2 Score\",r2S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228eb974",
   "metadata": {
    "id": "228eb974"
   },
   "outputs": [],
   "source": [
    "# Base models\n",
    "linear_model = LinearRegression()\n",
    "tree_model = DecisionTreeRegressor()\n",
    "forest_model = RandomForestRegressor()\n",
    "gradient_Boosting_model = GradientBoostingRegressor()\n",
    "svr_model = SVR()\n",
    "ridge_model = Ridge(alpha=0.5)\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "xgboost_model = XGBRFRegressor(n_estimators=100, random_state=42)\n",
    "adaboost_model = AdaBoostRegressor(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a849d72",
   "metadata": {},
   "source": [
    "## Ensebmle techniques before hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c5e219",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91c5e219",
    "outputId": "fe1b6333-8f05-4023-df5a-7781fab90f36"
   },
   "outputs": [],
   "source": [
    "# Model Averaging\n",
    "models = [linear_model, tree_model, forest_model,gradient_Boosting_model, svr_model, ridge_model, lasso_model, xgboost_model, adaboost_model ]\n",
    "averaged_predictions = np.zeros_like(y_test)\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    averaged_predictions = averaged_predictions.astype('float64')\n",
    "    averaged_predictions += predictions\n",
    "\n",
    "averaged_predictions /= len(models)\n",
    "averaged_mse = mean_squared_error(y_test, averaged_predictions)\n",
    "averaged_r2 = r2_score(y_test, averaged_predictions)\n",
    "\n",
    "print(\"Model Averaging MSE:\", averaged_mse)\n",
    "print(\"Model Averaging RMSE:\", averaged_mse**0.5)\n",
    "print(\"r2_score of Model Averaging\", averaged_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc310ec4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc310ec4",
    "outputId": "3c3f5162-0fa4-49a9-d327-d4ab2c037ae6"
   },
   "outputs": [],
   "source": [
    "# Stacking\n",
    "meta_model = LinearRegression()\n",
    "stacked_predictions = np.zeros_like(y_test)\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    stacked_predictions = np.column_stack((stacked_predictions, predictions))\n",
    "\n",
    "stacked_predictions = stacked_predictions[:, 1:]  # Remove the initial zeros column\n",
    "meta_model.fit(stacked_predictions, y_test)\n",
    "stacked_predictions = stacked_predictions.mean(axis=1)\n",
    "stacked_mse = mean_squared_error(y_test, stacked_predictions)\n",
    "stacked_r2 = r2_score(y_test, stacked_predictions)\n",
    "\n",
    "print(\"Stacking MSE:\", stacked_mse)\n",
    "print(\"Sqrt of Stacking RMSE:\", stacked_mse**0.5)\n",
    "print(\"r2_score of Stacking:\", stacked_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240ba7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e240ba7b",
    "outputId": "d0edc412-6aa7-4887-89a4-a67284ea373f"
   },
   "outputs": [],
   "source": [
    "# Weighted Voting\n",
    "weights = [0.2, 0.35, 0.45]  # Adjust the weights as desired\n",
    "weighted_predictions = np.zeros_like(y_test)\n",
    "model1 = [linear_model,gradient_Boosting_model, xgboost_model]\n",
    "for model, weight in zip(model1, weights):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    weighted_predictions = weighted_predictions.astype('float64')\n",
    "    weighted_predictions += weight * predictions\n",
    "\n",
    "weighted_mse = mean_squared_error(y_test, weighted_predictions)\n",
    "weighted_r2 = r2_score(y_test, weighted_predictions)\n",
    "\n",
    "print(\"Weighted Voting MSE:\", weighted_mse)\n",
    "print(\"Weighted Voting RMSE:\", weighted_mse**0.5)\n",
    "print(\"r2_score of Weighted Voting:\", weighted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278caa7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "278caa7f",
    "outputId": "9bb70b3b-a983-422d-d4b4-0b0e2eea46f0"
   },
   "outputs": [],
   "source": [
    "# Model Averaging only 3\n",
    "models = [linear_model, tree_model, forest_model,gradient_Boosting_model, svr_model, ridge_model, lasso_model, xgboost_model]\n",
    "averaged_predictions = np.zeros_like(y_test)\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    averaged_predictions = averaged_predictions.astype('float64')\n",
    "    averaged_predictions += predictions\n",
    "\n",
    "averaged_predictions /= len(models)\n",
    "averaged_mse = mean_squared_error(y_test, averaged_predictions)\n",
    "averaged_r2 = r2_score(y_test, averaged_predictions)\n",
    "\n",
    "print(\"Model Averaging MSE:\", averaged_mse)\n",
    "print(\"Model Averaging RMSE:\", averaged_mse**0.5)\n",
    "print(\"r2_score of Model Averaging\", averaged_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0cbe37",
   "metadata": {
    "id": "8b0cbe37"
   },
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680752f",
   "metadata": {
    "id": "4680752f"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7dc56d",
   "metadata": {},
   "source": [
    "# Hyperparameter Tunning for each Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08562c08",
   "metadata": {
    "id": "08562c08"
   },
   "source": [
    "## Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270b0ac",
   "metadata": {
    "id": "8270b0ac"
   },
   "outputs": [],
   "source": [
    "# Create a Lasso regression model and specify hyperparameter tuning using GridSearchCV\n",
    "lasso = Lasso()\n",
    "parameters = {\n",
    "    'alpha': [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 0, 1, 5, 10, 20, 30, 35, 40, 45, 50, 54, 55, 56, 57, 58, 59, 60, 70, 75, 77, 80, 90, 95, 100]\n",
    "}\n",
    "lasso_regression = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e97080",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b5e97080",
    "outputId": "45256875-9dda-43a3-df58-9269863b47dd"
   },
   "outputs": [],
   "source": [
    "# Fit the Lasso regression model with hyperparameter tuning to the training data\n",
    "lasso_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f54def",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4f54def",
    "outputId": "0bad168d-aa64-40d6-c041-79f903dfb5d3"
   },
   "outputs": [],
   "source": [
    "# Print the best hyperparameters, best score, and best estimator found during hyperparameter tuning\n",
    "print(\"Best Hyperparameters:\", lasso_regression.best_params_)\n",
    "print(\"Best Negative Mean Squared Error:\", lasso_regression.best_score_)\n",
    "print(\"Best Estimator:\", lasso_regression.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35efc4",
   "metadata": {
    "id": "be35efc4"
   },
   "outputs": [],
   "source": [
    "# Create a Lasso regression model and specify hyperparameter tuning using GridSearchCV\n",
    "lasso = Lasso()\n",
    "parameters = {\n",
    "    'alpha': [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 0, 1, 5, 10, 20, 30, 35, 40, 45, 50, 54, 55, 56, 57, 58, 59, 60, 70, 75, 77, 80, 90, 95, 100]\n",
    "}\n",
    "lasso_regression = GridSearchCV(lasso, parameters, scoring='r2', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe976c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Lasso regression model with hyperparameter tuning to the training data\n",
    "lasso_regression.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters, best score, and best estimator found during hyperparameter tuning\n",
    "print(\"Best Hyperparameters:\", lasso_regression.best_params_)\n",
    "print(\"Best R^2 Score:\", lasso_regression.best_score_)\n",
    "print(\"Best Estimator:\", lasso_regression.best_estimator_)\n",
    "\n",
    "# Create a Lasso regression model with a specific alpha value and fit it to the training data\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data using the Lasso model\n",
    "y_pred_l = lasso_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error between the predicted and actual values\n",
    "mse = mean_squared_error(y_test, y_pred_l)\n",
    "\n",
    "# Calculate the R^2 score between the predicted and actual values\n",
    "r2 = r2_score(y_test, y_pred_l)\n",
    "\n",
    "# Print the mean squared error and R^2 score\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Lasso regression model and specify hyperparameter tuning using GridSearchCV\n",
    "lasso = Lasso()\n",
    "parameters = {'alpha': np.linspace(-3, 3, 20)}  # Alpha values ranging from -3 to 3\n",
    "lasso_regression = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=10)\n",
    "\n",
    "# Fit the Lasso regression model with hyperparameter tuning to the training data\n",
    "lasso_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53621d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters, best score, and best estimator found during hyperparameter tuning\n",
    "print(\"Best Hyperparameters:\", lasso_regression.best_params_)\n",
    "print(\"Best Negative Mean Squared Error:\", lasso_regression.best_score_)\n",
    "print(\"Best Estimator:\", lasso_regression.best_estimator_)\n",
    "\n",
    "# Create a Lasso regression model with a specific alpha value (0.1) and fit it to the training data\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data using the Lasso model\n",
    "y_pred_LaT = lasso_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error between the predicted and actual values\n",
    "mse = mean_squared_error(y_test, y_pred_LaT)\n",
    "\n",
    "# Calculate the R^2 score between the predicted and actual values\n",
    "r2 = r2_score(y_test, y_pred_LaT)\n",
    "\n",
    "# Print the mean squared error and R^2 score\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b94be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store training and testing scores\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Generate a range of alpha values from -3 to 3 with 20 values\n",
    "alphas = np.linspace(-3, 3, 20)\n",
    "\n",
    "# Display the alpha values\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af38df1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 688
    },
    "id": "8af38df1",
    "outputId": "95360f5d-c7ec-4ffa-b53c-925a9a8f7bcd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a range of alpha values to explore\n",
    "alphas = np.logspace(-3, 3, num=20)\n",
    "\n",
    "# Create empty lists to store the R2 scores for training and test sets\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Iterate over the alpha values, fit the model, and calculate the R2 scores\n",
    "for alpha in alphas:\n",
    "    model = Lasso(alpha = alpha)  # Use your desired model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate R2 scores for training and test sets\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_score = r2_score(y_train, train_pred)\n",
    "    test_score = r2_score(y_test, test_pred)\n",
    "\n",
    "    # Append scores to the lists\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "# Plot the R2 scores versus alpha\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(alphas, train_scores, label='Training Set')\n",
    "plt.plot(alphas, test_scores, label='Test Set')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('R2 Score')\n",
    "#plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.title('R2 Score vs. Alpha')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97915a9b",
   "metadata": {
    "id": "97915a9b"
   },
   "source": [
    "## CV on Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ecf1b",
   "metadata": {
    "id": "ba8ecf1b"
   },
   "outputs": [],
   "source": [
    "random_forest =RandomForestRegressor()\n",
    "# parameters={'n_estimators':[100, 200 , 300], 'max_depth' : [3,5,7], 'criterion' : ['mse', 'mae']}\n",
    "parameters={'n_estimators':[100, 200 , 300], 'max_depth' : [3,5,7]}\n",
    "random_forest_regression=GridSearchCV(random_forest,parameters,scoring='r2',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267379ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "267379ad",
    "outputId": "06df1666-c3b2-4bd2-ddb0-5149ce9cd827",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_forest_regression.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2f439",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcf2f439",
    "outputId": "e1cba29d-14d8-4ec3-db12-b8e794862334"
   },
   "outputs": [],
   "source": [
    "print(random_forest_regression.best_params_)\n",
    "print(random_forest_regression.best_score_)\n",
    "print(random_forest_regression.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f70a6",
   "metadata": {
    "id": "529f70a6"
   },
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestRegressor(n_estimators=200, max_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b1068",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "e53b1068",
    "outputId": "43e7c62f-2042-4838-ee1e-d5f07921471d"
   },
   "outputs": [],
   "source": [
    "random_forest_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86864692",
   "metadata": {
    "id": "86864692"
   },
   "outputs": [],
   "source": [
    "y_pred_r = random_forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532886f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "532886f6",
    "outputId": "975bd0c6-95fb-4afc-98c7-5b947ace58ac"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,y_pred_r )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f93dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "395f93dd",
    "outputId": "a4e55adc-2e05-471e-e847-6fad756c29b0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359c9a6",
   "metadata": {
    "id": "a359c9a6"
   },
   "outputs": [],
   "source": [
    "#without passing any parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de8b9b",
   "metadata": {
    "id": "58de8b9b"
   },
   "outputs": [],
   "source": [
    "random_forest_model2 = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c79d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "499c79d1",
    "outputId": "010a0cdf-b722-4d3e-c847-1cc4fbf10e66"
   },
   "outputs": [],
   "source": [
    "random_forest_model2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d302def",
   "metadata": {
    "id": "2d302def"
   },
   "outputs": [],
   "source": [
    "y_pred_r2 = random_forest_model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7198ece7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7198ece7",
    "outputId": "d0cb342a-a406-4341-dacf-ec7fbd726131"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,y_pred_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a59757",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5a59757",
    "outputId": "f2a9af6a-c540-47e3-81f8-96e924af8582"
   },
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323295ae",
   "metadata": {
    "id": "323295ae"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters to tune and their ranges\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [ 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116b87a",
   "metadata": {
    "id": "f116b87a"
   },
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f6c17",
   "metadata": {
    "id": "a21f6c17"
   },
   "outputs": [],
   "source": [
    "# Iterate over the hyperparameter combinations, fit the Random Forest Regressor, and calculate the R2 scores\n",
    "for params in param_grid.values():\n",
    "    for param_value in params:\n",
    "        # Create a dictionary with the current hyperparameter value\n",
    "        param_dict = {list(param_grid.keys())[0]: param_value}\n",
    "\n",
    "        # Create the Random Forest Regressor with the specified hyperparameters\n",
    "        model = RandomForestRegressor(**param_dict)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the training and test sets\n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate the R2 scores for training and test sets\n",
    "        train_score = r2_score(y_train, train_pred)\n",
    "        test_score = r2_score(y_test, test_pred)\n",
    "\n",
    "        # Append the scores to the respective lists\n",
    "        train_scores.append(train_score)\n",
    "        test_scores.append(test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd94c44c",
   "metadata": {
    "id": "fd94c44c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot the R2 scores versus the corresponding hyperparameter values\n",
    "param_values = range(len(train_scores))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(param_values, train_scores, label='Training Set')\n",
    "plt.plot(param_values, test_scores, label='Test Set')\n",
    "plt.xlabel('Hyperparameter Combination')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.legend()\n",
    "plt.title('R2 Score vs. Hyperparameter Combination')\n",
    "plt.xticks(param_values, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b786ba85",
   "metadata": {
    "id": "b786ba85"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9652036b",
   "metadata": {
    "id": "9652036b"
   },
   "source": [
    "## CV on Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e349bef5",
   "metadata": {
    "id": "e349bef5"
   },
   "outputs": [],
   "source": [
    "ridge=Ridge()\n",
    "parameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,0,1,5,10,20,30,35,40,45,50,54,55,56,57,58,59,60,70,75,77,80,90,95,100]}\n",
    "ridge_regression=GridSearchCV(ridge,parameters,scoring='neg_mean_squared_error',cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b35ee1",
   "metadata": {
    "id": "51b35ee1"
   },
   "outputs": [],
   "source": [
    "ridge_regression.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82652b32",
   "metadata": {
    "id": "82652b32"
   },
   "outputs": [],
   "source": [
    "print(ridge_regression.best_params_)\n",
    "print(ridge_regression.best_score_)\n",
    "print(ridge_regression.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d59f3d",
   "metadata": {
    "id": "c7d59f3d"
   },
   "outputs": [],
   "source": [
    "ridge_model =Ridge(alpha = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee51ff3",
   "metadata": {
    "id": "2ee51ff3"
   },
   "outputs": [],
   "source": [
    "ridge_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f83f6",
   "metadata": {
    "id": "c95f83f6"
   },
   "outputs": [],
   "source": [
    "y_pred_ri = ridge_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e434ed",
   "metadata": {
    "id": "10e434ed"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred_ri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70a351",
   "metadata": {
    "id": "2d70a351"
   },
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred_ri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb045a00",
   "metadata": {
    "id": "fb045a00"
   },
   "outputs": [],
   "source": [
    "# Base models\n",
    "forest_model = RandomForestRegressor()\n",
    "ridge_model = Ridge(alpha=5)\n",
    "lasso_model = Lasso(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3de6b",
   "metadata": {
    "id": "9cd3de6b"
   },
   "outputs": [],
   "source": [
    "# Model Averaging\n",
    "models = [forest_model, ridge_model, lasso_model]\n",
    "averaged_predictions = np.zeros_like(y_test)\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    averaged_predictions = averaged_predictions.astype('float64')\n",
    "    averaged_predictions += predictions\n",
    "\n",
    "averaged_predictions /= len(models)\n",
    "averaged_mse = mean_squared_error(y_test, averaged_predictions)\n",
    "averaged_r2 = r2_score(y_test, averaged_predictions)\n",
    "\n",
    "print(\"Model Averaging MSE:\", averaged_mse)\n",
    "print(\"Model Averaging RMSE:\", averaged_mse**0.5)\n",
    "print(\"r2_score of Model Averaging\", averaged_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1189614",
   "metadata": {
    "id": "f1189614"
   },
   "outputs": [],
   "source": [
    "# Stacking\n",
    "meta_model = LinearRegression()\n",
    "stacked_predictions = np.zeros_like(y_test)\n",
    "models = [forest_model, ridge_model, lasso_model]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    stacked_predictions = np.column_stack((stacked_predictions, predictions))\n",
    "\n",
    "stacked_predictions = stacked_predictions[:, 1:]  # Remove the initial zeros column\n",
    "meta_model.fit(stacked_predictions, y_test)\n",
    "stacked_predictions = stacked_predictions.mean(axis=1)\n",
    "stacked_mse = mean_squared_error(y_test, stacked_predictions)\n",
    "stacked_r2 = r2_score(y_test, stacked_predictions)\n",
    "\n",
    "print(\"Stacking MSE:\", stacked_mse)\n",
    "print(\"Sqrt of Stacking RMSE:\", stacked_mse**0.5)\n",
    "print(\"r2_score of Stacking:\", stacked_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08710126",
   "metadata": {
    "id": "08710126"
   },
   "outputs": [],
   "source": [
    "# Weighted Voting\n",
    "weights = [0.7, 0.2, 0.1]  # Adjust the weights as desired\n",
    "weighted_predictions = np.zeros_like(y_test)\n",
    "models = [forest_model, lasso_model, ridge_model ]\n",
    "for model, weight in zip(models, weights):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    weighted_predictions = weighted_predictions.astype('float64')\n",
    "    weighted_predictions += weight * predictions\n",
    "\n",
    "weighted_mse = mean_squared_error(y_test, weighted_predictions)\n",
    "weighted_r2 = r2_score(y_test, weighted_predictions)\n",
    "\n",
    "print(\"Weighted Voting MSE:\", weighted_mse)\n",
    "print(\"Weighted Voting RMSE:\", weighted_mse**0.5)\n",
    "print(\"r2_score of Weighted Voting:\", weighted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c681545",
   "metadata": {
    "id": "5c681545"
   },
   "outputs": [],
   "source": [
    "forest_model = RandomForestRegressor()\n",
    "ridge_model = Ridge(alpha=5)\n",
    "lasso_model = Lasso(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e96d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863df307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model using Pickle\n",
    "with open('trained_RandomForest.pickle', 'wb') as file:\n",
    "    pickle.dump(forest_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7879deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model using Pickle\n",
    "with open('trained_Ridge_model.pickle', 'wb') as file:\n",
    "    pickle.dump(ridge_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25843400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model using Pickle\n",
    "with open('trained_Lasso_model.pickle', 'wb') as file:\n",
    "    pickle.dump(lasso_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e60a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model using Pickle\n",
    "with open('trained_Sc.pickle', 'wb') as file:\n",
    "    pickle.dump(sc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1696002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
